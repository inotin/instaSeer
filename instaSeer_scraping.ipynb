{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from instascrape import Profile, scrape_posts \n",
    "from selenium.webdriver import Chrome\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading posts objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPosts(accountNames, driverpath=\"/Users/inotin/Dropbox/DS/Personal/imageRecognition/chromedriver\", \n",
    "             sessionId = '17483229%3AsvgO9DB4dOd9T8%3A0', numOfPosts = 300):\n",
    "    \"\"\"\n",
    "    The function returns a dictionary with account names as keys and list of Post objects as value\n",
    "    Input:\n",
    "    accountNames (list(str)): list of instagram account names to be scraped\n",
    "    driverpath (str):         path to Selenium webdriver, default: \"/chromedriver\"\n",
    "    sessionId (str):          Session ID which is accepted by Instagram and allows scraping the data.\n",
    "                              It can be found in cookies section of developer's tools of your browser \n",
    "                              with opened instagram page \n",
    "    numOfPosts (int):         Number of Post objects to be downoaded for each account\n",
    "    \n",
    "    Output:\n",
    "    dictionary {'account1':[Post1,Post2,...], 'account2':[Post1, Post2,...],...}\n",
    "    \"\"\"\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Mobile Safari/537.36 Edg/87.0.664.57\",\n",
    "           \"cookie\": f\"sessionid={sessionId};\"}\n",
    "    webdriver = Chrome(driverpath)\n",
    "    dfComplete = pd.DataFrame()\n",
    "    \n",
    "    postsDct = defaultdict(list)\n",
    "    for account in accountNames:\n",
    "        postsList = []\n",
    "        profile = Profile(account)\n",
    "        profile.scrape(headers=headers)\n",
    "        posts = profile.get_posts(amount=numOfPosts, webdriver=webdriver, login_first= True)\n",
    "        postsDct[account].append(posts)\n",
    "        \n",
    "        print(f\"Posts loaded for {account}:\", len(posts))\n",
    "        fileNameTail = '_'.join(accountNames)\n",
    "    with open(f'postsList_{int(time.time())}_{fileNameTail}.pkl', 'wb') as f:\n",
    "        pickle.dump(postsDct, f)\n",
    "        \n",
    "#     dct = defaultdict(list)\n",
    "#     for posts in postsList:\n",
    "#         for post in tqdm(posts):\n",
    "#             try:\n",
    "#                 post.scrape(headers=headers)\n",
    "#                 d = post.to_dict()\n",
    "#                 for k in d:\n",
    "#                     dct[k].append(d[k])\n",
    "#                 dct['timestepOfDownloading'].append(time.time())\n",
    "#             except:\n",
    "#                 print('skipped', post)\n",
    "#         dfM = pd.DataFrame(dct)\n",
    "#         dfM.to_pickle(f'{int(time.time())}_{account}.pkl')\n",
    "#         dfComplete=pd.concat([dfComplete, dfM])\n",
    "#     dfComplete.to_pickle(f'{int(time.time())}_complete.pkl')\n",
    "    \n",
    "    return postsDct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapePosts(account, posts, \n",
    "                SESSIONID = '17483229%3AOHlfpimTdGEoN4%3A21', \n",
    "                additionalSessionIDs = ['17483229%3AOHlfpimTdGEoN4%3A21']):\n",
    "    \"\"\"\n",
    "    The function returns a dataframe containing columns with metadata obtained from Post objects in posts list\n",
    "    for certain account.\n",
    "    \n",
    "    Input:\n",
    "    account (str):               account name\n",
    "    posts (list(Post)):          list of Post objects\n",
    "    SESSIONID (str):             Session ID which is accepted by Instagram and allows scraping the data.\n",
    "                                 It can be found in cookies section of developer's tools of your browser \n",
    "                                 with opened instagram page\n",
    "    additionalSessionIDs (list): list of additional session id's (strings) which can be used during \n",
    "                                 scraping if primary session ID is rejected.\n",
    "    \n",
    "    Output:\n",
    "    pandas dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    dct = defaultdict(list)\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Mobile Safari/537.36 Edg/87.0.664.57\",\n",
    "               \"cookie\": f\"sessionid={SESSIONID};\"}\n",
    "    cntSkipped = 0 #Counter of skipped posts\n",
    "    \n",
    "    for i,post in tqdm(enumerate(posts), total = len(posts)):\n",
    "        try:\n",
    "            time.sleep(5*random.random()) #This adds some randomness which is useful to avoid blockinf from Instagram\n",
    "            post.scrape(headers=headers)\n",
    "            d = post.to_dict()\n",
    "            for k in d:\n",
    "                dct[k].append(d[k])\n",
    "            dct['loadTimestamp'].append(time.time()) #Current time to know when it was loaded\n",
    "            if i!=0 and i%100 == 0: #Every 100 scraped posts are saved separately, kind of checkpoints\n",
    "                dfM = pd.DataFrame(dct)\n",
    "                dfM.to_pickle(f'{int(time.time())}_{account}_{i}.pkl')\n",
    "                print(f'{int(time.time())}_{account}_{i}.pkl saved successfully')\n",
    "        except:\n",
    "            cntSkipped+=1\n",
    "            print(f'skipped in total: {cntSkipped}')\n",
    "            if cntSkipped>=5:\n",
    "                #If Instagram rejects requests, I try to change Session ID\n",
    "                headers = {\"user-agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Mobile Safari/537.36 Edg/87.0.664.57\",\n",
    "               \"cookie\": f\"sessionid={random.sample(additionalSessionIDs,1)[0]};\"}\n",
    "                \n",
    "    dfM = pd.DataFrame(dct)\n",
    "    dfM.to_pickle(f'{int(time.time())}_{account}.pkl') #This is the entire dataframe\n",
    "    return dfM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts loaded for visitcalifornia: 400\n",
      "Posts loaded for visitseattle: 400\n",
      "Posts loaded for japantravelcom: 400\n",
      "Posts loaded for visit_singapore: 400\n"
     ]
    }
   ],
   "source": [
    "listOfAccounts = ['visitcalifornia','visitseattle', 'japantravelcom', 'visit_singapore']\n",
    "postsDictionary = getPosts(listOfAccounts, numOfPosts=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loading previously saved posts\n",
    "# with open('postsList_1622978031_visitcalifornia_visitseattle_japantravelcom_visit_singapore.pkl', 'rb') as f:\n",
    "#     postsDictionary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a964ee8581f460888bbee6cd381eca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped in total: 1\n",
      "skipped in total: 2\n",
      "skipped in total: 3\n",
      "skipped in total: 4\n"
     ]
    }
   ],
   "source": [
    "dfComplete = pd.DataFrame()\n",
    "for account in postsDictionary:\n",
    "    if account == 'japantravelcom' or account=='visit_singapore':\n",
    "        pd.concat([dfComplete, scrapePosts(account, postsDictionary[account][0])])\n",
    "dfComplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
